{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/football_db_to_csv.py\n",
    "fbdb_stats_old = pd.read_csv('../../data/football_db_player_stats_11_22.csv')\n",
    "fbdb_stats = pd.read_csv('../../data/football_db_player_stats_12_05.csv')\n",
    "\n",
    "fbdb_stats_old['filter_date'] = pd.to_datetime(fbdb_stats_old['date'])\n",
    "fbdb_stats['filter_date'] = pd.to_datetime(fbdb_stats['date'])\n",
    "\n",
    "# Append new records to old records\n",
    "merge_df = pd.merge(fbdb_stats, fbdb_stats_old[['url', 'filter_date']], how='outer', on=['url', 'filter_date'], indicator=True)\n",
    "new_stats = merge_df[lambda df: df['_merge'] == 'left_only']\n",
    "fbdb_stats_new = pd.concat((fbdb_stats_old, new_stats), sort=False)\n",
    "fbdb_stats_new.drop(columns=['filter_date', '_merge'], inplace=True)\n",
    "\n",
    "fbdb_stats_new.to_csv('../../data/football_db_player_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player List\n",
    "**NOT CURRENTLY USED**\n",
    "- Positions: QB, RB (and variants), WR (and variants), TE\n",
    "- Keep unique ids because players can be labelled under multiple variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/player_links.json', 'r') as f:\n",
    "    players = []\n",
    "    for line in f:\n",
    "        players.append(json.loads(line))\n",
    "        \n",
    "players = pd.DataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_tracked =  ['QB', 'RB', 'GLB', '3RB', 'FB', 'WR1', 'WR2', 'WR3', 'TE']\n",
    "players = players.loc[lambda df: df.player_position.isin(positions_tracked), :]\n",
    "players['player_position'].replace(['GLB', '3RB', 'FB', 'WR1', 'WR2', 'WR3'], ['RB', 'RB', 'RB', 'WR', 'WR', 'WR'], inplace=True)\n",
    "players['player_id'] = players['player_link'].str.extract('([\\d]+)', expand=False)\n",
    "players.drop_duplicates('player_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(players.shape)\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv('../../data/player_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Stats\n",
    "**NOT CURRENTLY USED. See football_db_player_stats.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/player_stats.json', 'r') as f:\n",
    "    weekly_stats = []\n",
    "    for line in f:\n",
    "        weekly_stats.append(json.loads(line))\n",
    "        \n",
    "weekly_stats = pd.DataFrame(weekly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats['player_id'] = weekly_stats['url'].str.extract('([\\d]+)', expand=False)\n",
    "weekly_stats['away_game'] = weekly_stats['opp'].str.contains('@')\n",
    "weekly_stats['opp'] = weekly_stats['opp'].str.replace('@', '')\n",
    "weekly_stats['date'] = pd.to_datetime(weekly_stats['date'] + ' 2018', format='%b %d %Y')\n",
    "weekly_stats = weekly_stats[weekly_stats['player_id'].isin(players['player_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_in_order = ['player_id', 'player', 'date', 'week', 'opp', 'away_game', \n",
    "                 'pass_attempts', 'pass_completions', 'pass_percent',  'pass_yards', 'pass_ya', 'pass_td', 'pass_int',\n",
    "                 'rush_attempts', 'rush_yards', 'rush_avg', 'rush_td', \n",
    "                 'reception', 'rec_yards', 'rec_avg', 'rec_td', \n",
    "                 'fumb_lost', 'ko_ret_td', 'ko_ret_yards', 'punt_ret_td', 'punt_ret_yards']\n",
    "\n",
    "if all([True if col in weekly_stats.columns else False for col in cols_in_order]):\n",
    "    weekly_stats = weekly_stats[cols_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weekly_stats.loc['pass_attempts' : 'punt_ret_yards']:\n",
    "    weekly_stats[col] = weekly_stats[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weekly_stats.shape)\n",
    "weekly_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats.to_csv('../../data/player_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game_count = players.copy()\n",
    "stats_group = weekly_stats.groupby('player_id').size()\n",
    "stats_group = stats_group.reset_index()\n",
    "stats_group.rename(columns={0: 'game_count'}, inplace=True)\n",
    "player_game_count = player_game_count.merge(stats_group, how='left', on='player_id')\n",
    "player_game_count['game_count'].fillna(0, inplace=True)\n",
    "\n",
    "# Histogram of game stats per player\n",
    "player_game_count['game_count'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player News\n",
    "\n",
    "- Need to filter news updates down to game updates\n",
    "- Some players might not have game news updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/player_news_12_05.json', 'r') as f:\n",
    "    news = []\n",
    "    for line in f:\n",
    "        news.append(json.loads(line))\n",
    "        \n",
    "news = pd.DataFrame(news)\n",
    "news.set_index(news.index[::-1], inplace=True)\n",
    "news.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['player_id'] = news['url'].str.extract('([\\d]+)', expand=False)\n",
    "# Different entries have different time formats. One format is missing year\n",
    "news['date2'] = pd.to_datetime(news['date'], errors='coerce', format='%a, %b %d, %Y %I:%M:%S %p')\n",
    "news['date3'] = pd.to_datetime(news['date'], errors='coerce', format='%b %d - %I:%M %p')\n",
    "\n",
    "news = news[news['player_id'].isin(players['player_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dates(group):\n",
    "    new_dates = []\n",
    "    prev_year = None\n",
    "    prev_month = None\n",
    "    \n",
    "    for row in group.itertuples():\n",
    "        if row.date2 is not pd.NaT:\n",
    "            prev_year = row.date2.year\n",
    "            prev_month = row.date2.month\n",
    "            new_dates.append(pd.NaT)\n",
    "        elif row.date3 is not pd.NaT and prev_year is not None and prev_month is not None:\n",
    "            if row.date3.month >= prev_month:\n",
    "                new_dates.append(pd.to_datetime(str(prev_year) + str(row.date3)[4:]))\n",
    "            else:\n",
    "                new_dates.append(pd.to_datetime(str(prev_year + 1) + str(row.date3)[4:]))\n",
    "        else:\n",
    "            new_dates.append(row.date3)\n",
    "    \n",
    "    future_year = None\n",
    "    future_moth = None\n",
    "    new_dates = new_dates[::-1]\n",
    "    for i, row in enumerate(group[::-1].itertuples()):\n",
    "        if row.date2 is not pd.NaT:\n",
    "            future_year = row.date2.year\n",
    "            future_month = row.date2.month\n",
    "        elif row.date3 is not pd.NaT and future_year is not None and future_month is not None and new_dates[i] is pd.NaT:\n",
    "            if row.date3.month <= future_month:\n",
    "                new_dates[i] = pd.to_datetime(str(future_year) + str(row.date3)[4:])\n",
    "            else:\n",
    "                new_dates[i] = pd.to_datetime(str(future_year - 1) + str(row.date3)[4:])\n",
    "                \n",
    "    return pd.DataFrame(new_dates[::-1], index=group.index, columns=['new_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code assumes chronological order by player. Use this to populate missing year values\n",
    "grouped_news = news.groupby('player_id')\n",
    "output = grouped_news.apply(fill_dates)\n",
    "\n",
    "news['new_dates'] = output['new_dates']\n",
    "# For players with news entries only in the no year format. Assume year = 2018\n",
    "news['new_dates'] = np.where(np.logical_and(news['new_dates'].notna(), news['new_dates'].dt.year == 1900),\n",
    "                             pd.to_datetime('2018' + news['new_dates'].dt.strftime('%Y-%m-%d %H:%M:%S').str[4:]), news['new_dates'])\n",
    "\n",
    "# Combine final date column and drop temp columns\n",
    "news['date'] = np.where(news['date2'].notna(), news['date2'], news['new_dates'])\n",
    "news.drop(columns=['date2', 'date3', 'new_dates'], inplace=True)\n",
    "\n",
    "# Filter news before the 2018-2019 season\n",
    "news = news[news['date'] >= pd.to_datetime('2018-09-06')]\n",
    "\n",
    "# Filter news on game day\n",
    "#news['game_date'] = news['date'].dt.date\n",
    "#weekly_stats['game_date'] = weekly_stats['date'].dt.date\n",
    "#news = pd.merge(news, weekly_stats[['player_id', 'game_date']], how='inner', on=['player_id', 'game_date'])\n",
    "#news.drop(columns='game_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_old = news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new records to old records\n",
    "merge_df = pd.merge(news, news_old[['url', 'date']], how='outer', on=['url', 'date'], indicator=True)\n",
    "new_news = merge_df[lambda df: df['_merge'] == 'left_only']\n",
    "news_new = pd.concat((news_old, new_news), sort=False)\n",
    "news_new.drop(columns=['_merge'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_new.shape)\n",
    "news_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv('../../data/player_news_12_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_news_count = players.copy()\n",
    "news_group = news.groupby('player_id').size()\n",
    "news_group = news_group.reset_index()\n",
    "news_group.rename(columns={0: 'news_count'}, inplace=True)\n",
    "player_news_count = player_news_count.merge(news_group, how='left', on='player_id')\n",
    "player_news_count['news_count'].fillna(0, inplace=True)\n",
    "\n",
    "# Histogram of game summary news updates per player\n",
    "player_news_count['news_count'].value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fantasy_nlg]",
   "language": "python",
   "name": "conda-env-fantasy_nlg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
