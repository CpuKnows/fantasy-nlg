{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, namedtuple\n",
    "from itertools import chain\n",
    "import ftfy\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from string import Template\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import create_news_stats_dataset, create_inverted_news_dict, get_teams\n",
    "from src.spacy_utils import load_spacy_model\n",
    "from src.generate_templates import GenerateTemplates, get_context, get_context_tags, text_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_spacy_model('../../data/teams_aliases.txt', '../../data/player_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_stats_df = create_news_stats_dataset('../../data/player_news.csv', '../../data/football_db_player_stats.csv',\n",
    "#                                          '../../data/news_and_stats.csv')\n",
    "news_stats_df = pd.read_csv('../../data/news_and_stats.csv')\n",
    "news_stats_df = news_stats_df[lambda df: df['week'] < 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TemplateModel = namedtuple('TemplateModel', ['vectorizer', 'classifier'])\n",
    "def noop(d):\n",
    "    return d\n",
    "\n",
    "with open('../../models/ngram_nb.pkl', 'rb') as f:\n",
    "    TemplateModel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_generator = GenerateTemplates(nlp, '../../data/teams_aliases.txt', vectorizer=TemplateModel.vectorizer, clf=TemplateModel.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = template_generator.template_transformer(news_stats_df, '../../data/temp_templates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dict = news_stats_df.loc[13].to_dict()\n",
    "inverted_news_dict = create_inverted_news_dict(news_dict, \n",
    "                                               template_generator.data_cols, \n",
    "                                               template_generator.team_id_dict,\n",
    "                                               template_generator.id_team_dict)\n",
    "\n",
    "normalized_text = text_normalization(news_dict['report'])\n",
    "\n",
    "doc = nlp(normalized_text)\n",
    "\n",
    "doc = template_generator.template_tagging(doc, inverted_news_dict, training=False)\n",
    "news_template = template_generator.doc_to_template(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc)\n",
    "print()\n",
    "print(news_template.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2\n",
    "def r2(chunks, i):\n",
    "    tag_types = [None, 'player', 'game', 'passing', 'rushing', 'receptions']\n",
    "    encoding = [0] * len(tag_types)\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        if idx == i:\n",
    "            break\n",
    "        encoding[tag_types.index(chunk._.record_type)] = 1\n",
    "\n",
    "    encoding\n",
    "    \n",
    "# R3\n",
    "def r3(chunks, i):\n",
    "    i_tag_type = chunks[i].record_type\n",
    "    if i_tag_type is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            if chunk._.record_type == i_tag_type:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "# R4\n",
    "def r4(chunk_i):\n",
    "    chunk_values\n",
    "    for token in chunk_i:\n",
    "        if token._.template_tag is not None:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_templates = pd.read_csv('../../data/nbmodel_templates.csv')\n",
    "output_templates.rename(index=str, columns={'reports': 'report'}, inplace=True)\n",
    "asdf = pd.merge(news_stats_df, output_templates, how='right', on='report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_col_types(text):\n",
    "    template_regex = re.compile(r'\\$\\{([_a-z][_a-z0-9]*)\\}')\n",
    "    tags = re.findall(template_regex, text)\n",
    "    return [template_generator.data_col_to_type[tag] for tag in tags]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fantasy_nlg]",
   "language": "python",
   "name": "conda-env-fantasy_nlg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
